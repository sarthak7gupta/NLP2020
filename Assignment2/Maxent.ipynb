{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from operator import getitem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'than', 'they', 'being', 'other', 'he', 't', 'myself', 'same', 'on', 'me', 'their', 'have', 'before', 'then', 'been', \"it's\", 'any', 'both', 'just', 'y', 'is', 'which', 'off', \"you're\", 've', 'yours', 'was', 'of', 'below', 'themselves', 'there', 'at', 'will', 'ma', 'above', 'you', 'now', 'll', 'we', 'very', 'over', 'these', 'it', 'until', 'as', 'that', 'himself', 'ours', 'once', \"you've\", 'did', 'under', 'o', 'after', 'down', 'be', 'from', 'when', 'about', \"you'll\", 'herself', 'through', 'his', 'ourselves', 'during', 'if', 'all', 'yourselves', 'my', 'where', 'our', 'those', 'out', 'the', 'your', 'so', 'doing', 'its', 'theirs', 'again', 're', 'with', 'and', 'him', \"that'll\", 'for', \"should've\", 'more', \"didn't\", 'yourself', 'here', 'up', 'by', 'while', 'in', 'd', 'into', 'further', 'too', 'do', 'them', 'does', 'but', 'most', 'what', 'having', 'her', 'why', 's', 'an', 'such', 'i', 'has', 'each', 'whom', 'few', 'she', \"she's\", 'because', 'between', 'how', 'a', 'or', 'some', 'had', \"you'd\", 'own', 'this', 'were', 'am', 'can', 'itself', 'only', 'who', 'are', 'to', 'm', 'hers', 'should'}\n"
     ]
    }
   ],
   "source": [
    "#necessary corpora\n",
    "\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "required = {\"needn\", \"doesn\", \"won\", \"shan't\", \"don\", \"ain\", \"not\", \"didn\", \"hadn\", \"haven't\", \"couldn't\", \"wasn't\", \"aren't\", \"isn\", \"needn't\", \"aren\", \"wouldn\", \"shouldn\", \"hasn't\", \"shan\", \"no\", \"wasn\", \"nor\", \"hasn\", \"mightn\", \"doesn't\", \"against\", \"wouldn't\", \"couldn\", \"hadn't\", \"isn't\", \"mustn\", \"don't\", \"weren't\", \"haven\", \"mustn't\", \"shouldn't\", \"weren\", \"won't\", \"mightn't\"}\n",
    "stopwords_set -= required\n",
    "print(stopwords_set)\n",
    "dictionary = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"FinalTweetList_train.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4493\n",
      "                                                       0              1\n",
      "0      Very nice job by @KotakBankLtd .\\nWhen #ATMs o...     compliment\n",
      "1      @ICICIBank_Care Amazing work at @ICICIBank Dah...     compliment\n",
      "2      @KotakBankLtd ur branch at vivek vihar was wel...     compliment\n",
      "3      Thank you @ICICIBank_Care  @ICICIBank  for rev...     compliment\n",
      "4      @ICICIBank @ICICIBank_Care i want to sincerely...     compliment\n",
      "...                                                  ...            ...\n",
      "14487  @AxisBank @HDFC_Bank @ICICIBank @IDBI_Bank @ID...  miscellaneous\n",
      "14488  Latest status of ATMs in Jangpura, New Delhi. ...  miscellaneous\n",
      "14489  I wonder why there is no queue @YESBANK Jalgao...  miscellaneous\n",
      "14490  @ndtv In queue since 7 AM @YESBANK out of curr...  miscellaneous\n",
      "14491  @ICICIBank @TheOfficialSBI @HDFC_Bank @AxisBan...  miscellaneous\n",
      "\n",
      "[14492 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#upsample compliments to equalise classes\n",
    "\n",
    "compliment = df[df[1]=='compliment']\n",
    "displeasure = df[df[1]=='displeasure']\n",
    "miscellaneous = df[df[1]=='miscellaneous']\n",
    "size = min(len(displeasure), len(miscellaneous))\n",
    "print(size)\n",
    "compliment_extra = pd.DataFrame()\n",
    "while(len(compliment) + len(compliment_extra) < size):\n",
    "    compliment_extra = compliment_extra.append(compliment.sample(min(size - (len(compliment) + len(compliment_extra)),len(compliment))))\n",
    "compliment = compliment_extra.append(compliment)\n",
    "\n",
    "df = compliment.append([displeasure, miscellaneous])\n",
    "df = df.reset_index(drop = True)\n",
    "print(df)\n",
    "\n",
    "# partially stratified upsample 80.5% train 74% test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncompliment = df[df[1]=='compliment']\\ndispleasure = df[df[1]=='displeasure']\\nmiscellaneous = df[df[1]=='miscellaneous']\\n_, displeasure = train_test_split(displeasure, test_size = len(compliment), random_state = 21)\\n_, miscellaneous = train_test_split(miscellaneous, test_size = len(compliment), random_state = 21)\\ndf = compliment.append([displeasure, miscellaneous])\\ndf = df.reset_index(drop = True)\\nprint(df)\\n\""
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#downsample displeasure and miscellaneous to equalise classes\n",
    "\n",
    "'''\n",
    "compliment = df[df[1]=='compliment']\n",
    "displeasure = df[df[1]=='displeasure']\n",
    "miscellaneous = df[df[1]=='miscellaneous']\n",
    "_, displeasure = train_test_split(displeasure, test_size = len(compliment), random_state = 21)\n",
    "_, miscellaneous = train_test_split(miscellaneous, test_size = len(compliment), random_state = 21)\n",
    "df = compliment.append([displeasure, miscellaneous])\n",
    "df = df.reset_index(drop = True)\n",
    "print(df)\n",
    "'''\n",
    "#stratified downsample 88.5% train 67.4% test\n",
    "#original 73.7% train 61.4% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       0              1\n",
      "0      very nice job by at_user . when atms of at_use...     compliment\n",
      "1      at_user amazing work at at_user dahisar west b...     compliment\n",
      "2      at_user ur branch at vivek vihar was well mana...     compliment\n",
      "3      thank you at_user at_user for reversing the ch...     compliment\n",
      "4      at_user at_user i want to sincerely appreciate...     compliment\n",
      "...                                                  ...            ...\n",
      "14487  at_user at_user at_user at_user at_user at_use...  miscellaneous\n",
      "14488  latest status of atms in jangpura, new delhi. ...  miscellaneous\n",
      "14489  i wonder why there is no queue at_user jalgaon...  miscellaneous\n",
      "14490  at_user in queue since 7 am at_user out of cur...  miscellaneous\n",
      "14491  at_user at_user at_user at_user at_user at_use...  miscellaneous\n",
      "\n",
      "[14492 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#tweet cleaning\n",
    "\n",
    "def processTweet(tweet):\n",
    "    #Convert www.* or https?://* to URL\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)\n",
    "    #Convert @username to AT_USER\n",
    "    tweet = re.sub('@[^\\s]+','AT_USER',tweet)\n",
    "    #Remove additional white spaces\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    #Replace #word with word\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    #trim\n",
    "    tweet = tweet.strip('\\'\"')\n",
    "    #Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    return tweet\n",
    "\n",
    "for i in range(len(df[0])):\n",
    "    df[0][i] = processTweet(df[0][i])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopword removal, non-alphabet tokens removed, optional non-english word removal, Maxent feature extraction\n",
    "\n",
    "#train, test = train_test_split(df, test_size = (500 if len(feats)>500 else 0.25), stratify = df[1], random_state = 21)\n",
    "#train, test = train_test_split(df, test_size = (500 if len(feats)>500 else 0.25), random_state = 21)\n",
    "#train = train.reset_index(drop = True)\n",
    "#test = test.reset_index(drop = True)\n",
    "train = df\n",
    "\n",
    "def word_feats(words):\n",
    "    #return {word:True for word in words if (word.isalpha())}    #downsample 87.5% train 66.8% test    upsample 75.7% train 71% test\n",
    "    #return {word:True for word in words if (word.isalpha() and word in dictionary)}    #downsample 81.6% train 66% test    upsample 70.8% train 69% test\n",
    "    return {word:True for word in words if (word.isalpha() and word not in stopwords_set)}    #downsample 88.5% train 67.4% test    upsample 80.5% train 74% test\n",
    "    #return {word:True for word in words if (word.isalpha() and word not in stopwords_set and word in dictionary)}    #downsample 82.4% train 63.4% test    upsample 75.3% train 68% test\n",
    "    \n",
    "def extract_feats(dataframe):\n",
    "    return [(word_feats(WordPunctTokenizer().tokenize(dataframe[0][i])), dataframe[1][i]) for i in range(len(dataframe[0]))]\n",
    "\n",
    "train_set = extract_feats(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (25 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -1.09861        0.310\n",
      "             2          -1.09806        0.830\n",
      "             3          -1.09751        0.830\n",
      "             4          -1.09696        0.830\n",
      "             5          -1.09641        0.830\n",
      "             6          -1.09587        0.830\n",
      "             7          -1.09532        0.830\n",
      "             8          -1.09477        0.830\n",
      "             9          -1.09422        0.830\n",
      "            10          -1.09368        0.830\n",
      "            11          -1.09313        0.830\n",
      "            12          -1.09259        0.830\n",
      "            13          -1.09204        0.830\n",
      "            14          -1.09150        0.830\n",
      "            15          -1.09095        0.830\n",
      "            16          -1.09041        0.830\n",
      "            17          -1.08986        0.830\n",
      "            18          -1.08932        0.830\n",
      "            19          -1.08878        0.830\n",
      "            20          -1.08824        0.830\n",
      "            21          -1.08769        0.830\n",
      "            22          -1.08715        0.830\n",
      "            23          -1.08661        0.830\n",
      "            24          -1.08607        0.830\n",
      "         Final          -1.08553        0.830\n",
      "  -0.018 pathetic==True and label is 'miscellaneous'\n",
      "  -0.017 chaos==True and label is 'miscellaneous'\n",
      "  -0.017 real==True and label is 'miscellaneous'\n",
      "  -0.016 min==True and label is 'miscellaneous'\n",
      "  -0.016 nation==True and label is 'miscellaneous'\n",
      "  -0.015 hell==True and label is 'miscellaneous'\n",
      "  -0.015 bankers==True and label is 'miscellaneous'\n",
      "  -0.015 resolve==True and label is 'miscellaneous'\n",
      "  -0.015 minutes==True and label is 'miscellaneous'\n",
      "  -0.015 proud==True and label is 'miscellaneous'\n"
     ]
    }
   ],
   "source": [
    "#Maxent train\n",
    "\n",
    "algorithm = nltk.classify.MaxentClassifier.ALGORITHMS[0]\n",
    "classifier = nltk.MaxentClassifier.train(train_set, algorithm, max_iter = 25)\n",
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Kotak Bank:  32.60% in  500 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   compliment       0.86      0.90      0.88       113\n",
      "  displeasure       0.73      0.92      0.81       232\n",
      "miscellaneous       0.82      0.48      0.60       155\n",
      "\n",
      "     accuracy                           0.78       500\n",
      "    macro avg       0.81      0.77      0.77       500\n",
      " weighted avg       0.79      0.78      0.76       500\n",
      "\n",
      "                             Axis Bank:  30.60% in  500 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   compliment       0.73      0.85      0.79        41\n",
      "  displeasure       0.79      0.95      0.86       201\n",
      "miscellaneous       0.95      0.78      0.85       258\n",
      "\n",
      "     accuracy                           0.85       500\n",
      "    macro avg       0.82      0.86      0.83       500\n",
      " weighted avg       0.87      0.85      0.85       500\n",
      "\n",
      "                             HDFC Bank:  27.70% in  500 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   compliment       0.60      0.89      0.72        61\n",
      "  displeasure       0.70      0.94      0.80       234\n",
      "miscellaneous       0.92      0.43      0.59       205\n",
      "\n",
      "     accuracy                           0.72       500\n",
      "    macro avg       0.74      0.75      0.70       500\n",
      " weighted avg       0.78      0.72      0.70       500\n",
      "\n",
      "                            ICICI Bank:  24.30% in  500 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   compliment       0.80      0.91      0.85        65\n",
      "  displeasure       0.81      0.97      0.88       278\n",
      "miscellaneous       0.92      0.55      0.69       157\n",
      "\n",
      "     accuracy                           0.83       500\n",
      "    macro avg       0.84      0.81      0.81       500\n",
      " weighted avg       0.84      0.83      0.82       500\n",
      "\n",
      "                   State Bank of India:  23.10% in  500 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   compliment       0.53      0.65      0.59        55\n",
      "  displeasure       0.64      0.90      0.74       238\n",
      "miscellaneous       0.86      0.40      0.54       207\n",
      "\n",
      "     accuracy                           0.66       500\n",
      "    macro avg       0.68      0.65      0.62       500\n",
      " weighted avg       0.72      0.66      0.64       500\n",
      "\n",
      "                 Reserve Bank of India:  22.53% in  253 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   compliment       0.66      0.86      0.75        22\n",
      "  displeasure       0.76      0.94      0.84       136\n",
      "miscellaneous       0.89      0.53      0.66        95\n",
      "\n",
      "     accuracy                           0.78       253\n",
      "    macro avg       0.77      0.78      0.75       253\n",
      " weighted avg       0.80      0.78      0.77       253\n",
      "\n",
      "                        Bank of Baroda:  28.62% in  138 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   compliment       0.60      0.78      0.68        23\n",
      "  displeasure       0.55      0.88      0.68        56\n",
      "miscellaneous       0.95      0.31      0.46        59\n",
      "\n",
      "     accuracy                           0.62       138\n",
      "    macro avg       0.70      0.65      0.61       138\n",
      " weighted avg       0.73      0.62      0.58       138\n",
      "\n",
      "                  Punjab National Bank:  42.11% in   19 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   compliment       0.60      0.75      0.67         4\n",
      "  displeasure       0.75      0.86      0.80         7\n",
      "miscellaneous       0.83      0.62      0.71         8\n",
      "\n",
      "     accuracy                           0.74        19\n",
      "    macro avg       0.73      0.74      0.73        19\n",
      " weighted avg       0.75      0.74      0.74        19\n",
      "\n",
      "                              Yes Bank:  42.11% in   19 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   compliment       0.60      0.75      0.67         4\n",
      "  displeasure       0.88      1.00      0.93         7\n",
      "miscellaneous       1.00      0.75      0.86         8\n",
      "\n",
      "     accuracy                           0.84        19\n",
      "    macro avg       0.83      0.83      0.82        19\n",
      " weighted avg       0.87      0.84      0.85        19\n",
      "\n",
      "                         IndusInd Bank:  15.38% in   13 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   compliment       1.00      1.00      1.00         1\n",
      "  displeasure       0.50      1.00      0.67         5\n",
      "miscellaneous       1.00      0.29      0.44         7\n",
      "\n",
      "     accuracy                           0.62        13\n",
      "    macro avg       0.83      0.76      0.70        13\n",
      " weighted avg       0.81      0.62      0.57        13\n",
      "\n",
      "                             IDBI Bank:  50.00% in   11 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   compliment       0.60      1.00      0.75         3\n",
      "  displeasure       0.80      1.00      0.89         4\n",
      "miscellaneous       1.00      0.25      0.40         4\n",
      "\n",
      "     accuracy                           0.73        11\n",
      "    macro avg       0.80      0.75      0.68        11\n",
      " weighted avg       0.82      0.73      0.67        11\n",
      "\n",
      "                              Citibank:  18.18% in   11 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   compliment       1.00      1.00      1.00         1\n",
      "  displeasure       0.88      0.88      0.88         8\n",
      "miscellaneous       0.50      0.50      0.50         2\n",
      "\n",
      "     accuracy                           0.82        11\n",
      "    macro avg       0.79      0.79      0.79        11\n",
      " weighted avg       0.82      0.82      0.82        11\n",
      "\n",
      "                         Bank of India:  16.67% in    6 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  displeasure       0.75      1.00      0.86         3\n",
      "miscellaneous       1.00      0.67      0.80         3\n",
      "\n",
      "     accuracy                           0.83         6\n",
      "    macro avg       0.88      0.83      0.83         6\n",
      " weighted avg       0.88      0.83      0.83         6\n",
      "\n",
      "                                 PayTM:  20.00% in    5 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   compliment       1.00      1.00      1.00         1\n",
      "  displeasure       0.50      1.00      0.67         2\n",
      "miscellaneous       0.00      0.00      0.00         2\n",
      "\n",
      "     accuracy                           0.60         5\n",
      "    macro avg       0.50      0.67      0.56         5\n",
      " weighted avg       0.40      0.60      0.47         5\n",
      "\n",
      "                           Vijaya Bank:  50.00% in    4 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   compliment       1.00      1.00      1.00         1\n",
      "  displeasure       1.00      1.00      1.00         1\n",
      "miscellaneous       1.00      1.00      1.00         2\n",
      "\n",
      "     accuracy                           1.00         4\n",
      "    macro avg       1.00      1.00      1.00         4\n",
      " weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "                           Canara Bank:  66.67% in    3 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   compliment       1.00      1.00      1.00         1\n",
      "miscellaneous       1.00      1.00      1.00         2\n",
      "\n",
      "     accuracy                           1.00         3\n",
      "    macro avg       1.00      1.00      1.00         3\n",
      " weighted avg       1.00      1.00      1.00         3\n",
      "\n",
      "                      Corporation Bank:  33.33% in    3 tweets\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  compliment       1.00      1.00      1.00         1\n",
      " displeasure       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         3\n",
      "   macro avg       1.00      1.00      1.00         3\n",
      "weighted avg       1.00      1.00      1.00         3\n",
      "\n",
      "                           Post Office:  16.67% in    3 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  displeasure       0.50      1.00      0.67         1\n",
      "miscellaneous       1.00      0.50      0.67         2\n",
      "\n",
      "     accuracy                           0.67         3\n",
      "    macro avg       0.75      0.75      0.67         3\n",
      " weighted avg       0.83      0.67      0.67         3\n",
      "\n",
      "                   Union Bank of India:  16.67% in    3 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  displeasure       1.00      1.00      1.00         2\n",
      "miscellaneous       1.00      1.00      1.00         1\n",
      "\n",
      "     accuracy                           1.00         3\n",
      "    macro avg       1.00      1.00      1.00         3\n",
      " weighted avg       1.00      1.00      1.00         3\n",
      "\n",
      "                        Allahabad Bank:  50.00% in    2 tweets\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  compliment       1.00      1.00      1.00         1\n",
      " displeasure       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "                          Federal Bank:  50.00% in    2 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "miscellaneous       1.00      1.00      1.00         2\n",
      "\n",
      "     accuracy                           1.00         2\n",
      "    macro avg       1.00      1.00      1.00         2\n",
      " weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "                         Oriental Bank:  50.00% in    2 tweets\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  compliment       1.00      1.00      1.00         1\n",
      " displeasure       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "                     Banking Ombudsman:  25.00% in    2 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  displeasure       1.00      1.00      1.00         1\n",
      "miscellaneous       1.00      1.00      1.00         1\n",
      "\n",
      "     accuracy                           1.00         2\n",
      "    macro avg       1.00      1.00      1.00         2\n",
      " weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "                              UCO Bank:  25.00% in    2 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  displeasure       1.00      1.00      1.00         1\n",
      "miscellaneous       1.00      1.00      1.00         1\n",
      "\n",
      "     accuracy                           1.00         2\n",
      "    macro avg       1.00      1.00      1.00         2\n",
      " weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "                          Central Bank:   0.00% in    2 tweets\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " displeasure       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "                                  HSBC:   0.00% in    2 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  displeasure       0.00      0.00      0.00       0.0\n",
      "miscellaneous       0.00      0.00      0.00       2.0\n",
      "\n",
      "     accuracy                           0.00       2.0\n",
      "    macro avg       0.00      0.00      0.00       2.0\n",
      " weighted avg       0.00      0.00      0.00       2.0\n",
      "\n",
      "National Payments Corporation of India:   0.00% in    2 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  displeasure       0.00      0.00      0.00       0.0\n",
      "miscellaneous       0.00      0.00      0.00       2.0\n",
      "\n",
      "     accuracy                           0.00       2.0\n",
      "    macro avg       0.00      0.00      0.00       2.0\n",
      " weighted avg       0.00      0.00      0.00       2.0\n",
      "\n",
      "                            World Bank: 100.00% in    1 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   compliment       0.00      0.00      0.00       0.0\n",
      "miscellaneous       0.00      0.00      0.00       1.0\n",
      "\n",
      "     accuracy                           0.00       1.0\n",
      "    macro avg       0.00      0.00      0.00       1.0\n",
      " weighted avg       0.00      0.00      0.00       1.0\n",
      "\n",
      "                       IDFC First Bank:  50.00% in    1 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "miscellaneous       1.00      1.00      1.00         1\n",
      "\n",
      "     accuracy                           1.00         1\n",
      "    macro avg       1.00      1.00      1.00         1\n",
      " weighted avg       1.00      1.00      1.00         1\n",
      "\n",
      "                              MobiKwik:  50.00% in    1 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "miscellaneous       1.00      1.00      1.00         1\n",
      "\n",
      "     accuracy                           1.00         1\n",
      "    macro avg       1.00      1.00      1.00         1\n",
      " weighted avg       1.00      1.00      1.00         1\n",
      "\n",
      "                   Bank of Maharashtra:   0.00% in    1 tweets\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " displeasure       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n",
      "                              DCB Bank:   0.00% in    1 tweets\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " displeasure       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n",
      "                  Indian Overseas Bank:   0.00% in    1 tweets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  displeasure       0.00      0.00      0.00       0.0\n",
      "miscellaneous       0.00      0.00      0.00       1.0\n",
      "\n",
      "     accuracy                           0.00       1.0\n",
      "    macro avg       0.00      0.00      0.00       1.0\n",
      " weighted avg       0.00      0.00      0.00       1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Maxent testing on all banks and performance index calculation from classifier predictions\n",
    "\n",
    "values = {\n",
    "    \"compliment\": 1,\n",
    "    \"miscellaneous\": 0.5,\n",
    "    \"displeasure\": 0\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "direc = os.fsencode('./test')\n",
    "for File in os.listdir(direc):\n",
    "    filename = os.fsdecode(File)\n",
    "    try:\n",
    "        test = pd.read_csv(\"./test/\" + filename, header = None)\n",
    "        for i in range(len(test[0])):\n",
    "            test[0][i] = processTweet(test[0][i])\n",
    "        test_set = extract_feats(test)\n",
    "        y_true = list(test[1])\n",
    "        y_pred = [classifier.classify(i[0]) for i in test_set]\n",
    "        sum = 0\n",
    "        for i in y_pred:\n",
    "            sum += values[i]\n",
    "        result = {}\n",
    "        result['performance_index'] = sum * 100 / len(y_pred)\n",
    "        result['classification_report'] = classification_report(y_true, y_pred)\n",
    "        result['tweets'] = len(y_pred)\n",
    "        results[filename[:-4]] = result\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for i in sorted(results.items(), key = lambda x: ( -(getitem(x[1],'tweets')), -(getitem(x[1],'performance_index')) )):\n",
    "    print((i[0] + \": \").rjust(40) + (\"{:.2f}\".format(i[1]['performance_index'])).rjust(6) + \"% in \" + str(i[1]['tweets']).rjust(4) + \" tweets\")\n",
    "    print(i[1]['classification_report'])\n",
    "    \n",
    "#Toppers are:\n",
    "    #1. Kotak Bank: 32.60%\n",
    "    #2. Axis Bank: 30.60%\n",
    "    #3. HDFC Bank: 27.70%\n",
    "    #4. ICICI Bank: 24.30%\n",
    "    #5. State Bank of India: 23.10%\n",
    "#Almost correct order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
