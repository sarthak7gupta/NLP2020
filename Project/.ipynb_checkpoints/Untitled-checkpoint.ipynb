{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'urlparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-230204276775>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munidecode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0murlparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'urlparse'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import contractions\n",
    "import unidecode\n",
    "import re\n",
    "import emoji\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sorry No Comments ..I came here to read commen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi guys. I'm so happy and proud of myself and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hahahaha your intelligence 😜😜😜</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aqsa Naveed we were proud backbenchers 😜😜😂</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hemant extraordinary sketcher😝..right Ujjawal??</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5466</th>\n",
       "      <td>fuck ps3 go get a xbox 360☺</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5467</th>\n",
       "      <td>Happy Bithday Windows 7.. I ♥ Windows 7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5468</th>\n",
       "      <td>I can't wait I'm soo excited! 😀😀😀</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5469</th>\n",
       "      <td>windows live is very good, I use it more than ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5470</th>\n",
       "      <td>I really enjoyed perusing this.Inspiring ♥♥♥</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10942 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  label\n",
       "0     Sorry No Comments ..I came here to read commen...      1\n",
       "1     Hi guys. I'm so happy and proud of myself and ...      1\n",
       "2                        Hahahaha your intelligence 😜😜😜      1\n",
       "3            Aqsa Naveed we were proud backbenchers 😜😜😂      1\n",
       "4       Hemant extraordinary sketcher😝..right Ujjawal??      1\n",
       "...                                                 ...    ...\n",
       "5466                        fuck ps3 go get a xbox 360☺      0\n",
       "5467            Happy Bithday Windows 7.. I ♥ Windows 7      0\n",
       "5468                  I can't wait I'm soo excited! 😀😀😀      0\n",
       "5469  windows live is very good, I use it more than ...      0\n",
       "5470       I really enjoyed perusing this.Inspiring ♥♥♥      0\n",
       "\n",
       "[10942 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = ['Final_Dataset_Facebook.csv', 'Final_Dataset_Facebook_Labels.csv']\n",
    "f2 = ['Final_Dataset_Twitter.csv', 'Final_Dataset_Twitter_Labels.csv']\n",
    "\n",
    "d11, d12 = pd.read_csv(f1[0]), pd.read_csv(f1[1])\n",
    "d21, d22 = pd.read_csv(f1[0]), pd.read_csv(f1[1])\n",
    "\n",
    "df1 = pd.concat([d11, d12], axis=1)\n",
    "df2 = pd.concat([d21, d22], axis=1)\n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "df.drop(columns=['Unnamed: 1'], inplace=True)\n",
    "\n",
    "df.columns = ['tweet', 'label']\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "deselect_stop_words = ['no', 'not']\n",
    "\n",
    "for w in deselect_stop_words:\n",
    "    nlp.vocab[w].is_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def strip_links(text):\n",
    "#     link_regex    = re.compile('((https?):((//)|(\\\\\\\\))+([\\w\\d:#@%/;$()~_?\\+-=\\\\\\.&](#!)?)*)', re.DOTALL)\n",
    "#     links         = re.findall(link_regex, text)\n",
    "#     for link in links:\n",
    "#         text = text.replace(link[0], ', ')    \n",
    "#     return text\n",
    "\n",
    "URL_REGEX = re.compile(\"(http:\\/\\/www\\.|https:\\/\\/www\\.|http:\\/\\/|https:\\/\\/)?[a-z0-9]+([\\-\\.]{1}[a-z0-9]+)*\\.[a-z]{2,5}(:[0-9]{1,5})?(\\/.*)?\", re.UNICODE)\n",
    "\n",
    "def cleanse_tags_mentions(text):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])\", \" \", text).split())\n",
    "#     return re.sub(r\"(?:@\\S*|#\\S*|http(?=.*://)\\S*)\", \"\", text)\n",
    "\n",
    "def cleanse_links(text):\n",
    "    return URL_REGEX.sub(r' ',text)\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "    # café -> cafe\n",
    "    return unidecode.unidecode(text)\n",
    "\n",
    "def expand_contractions(text):\n",
    "    # don't -> do not\n",
    "    return contractions.fix(text)\n",
    "\n",
    "def remove_excess_whitespace(text):\n",
    "    # '  ' -> ' '\n",
    "    return \" \".join(text.strip().split())\n",
    "\n",
    "def extract_emojis(sentence):\n",
    "    return [word for word in sentence.split() if str(word.encode('unicode-escape'))[2] == '\\\\' ]\n",
    "\n",
    "def char_is_emoji(character):\n",
    "    return character in emoji.UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry No Comments ..I came here to read comments ..😜\n",
      "Sorry No Comments I came here to read comments\n",
      "\n",
      "Hi guys. I'm so happy and proud of myself and I thought I should share this with you!!! Today, I saw myself on TV, when I turned it off. 😝😝\n",
      "Hi guys I m so happy and proud of myself and I thought I should share this with you Today I saw myself on TV when I turned it off\n",
      "\n",
      "Hahahaha your intelligence 😜😜😜\n",
      "Hahahaha your intelligence\n",
      "\n",
      "Aqsa Naveed we were proud backbenchers 😜😜😂\n",
      "Aqsa Naveed we were proud backbenchers\n",
      "\n",
      "Hemant extraordinary sketcher😝..right Ujjawal??\n",
      "Hemant extraordinary sketcher right Ujjawal\n",
      "\n",
      "Boys should respect them..!! 😜🔫\n",
      "Boys should respect them\n",
      "\n",
      "Your love bro😜\n",
      "Your love bro\n",
      "\n",
      "Bro u r handsome 😝🤣🤣\n",
      "Bro you r handsome\n",
      "\n",
      "This talent I don't have.. pls teach me Prani😜\n",
      "This talent I don t have pls teach me Prani\n",
      "\n",
      "Sunny Yadav wow wat an assumption😝\n",
      "Sunny Yadav wow wat an assumption\n",
      "\n",
      "I will try my best for u drling😜😂\n",
      "I will try my best for you drling\n",
      "\n",
      "U can do this, I trust you 😜\n",
      "you can do this I trust you\n",
      "\n",
      "Learning from my guru.. \"Happy teacher's Day \"😝\n",
      "Learning from my guru Happy teacher s Day\n",
      "\n",
      "Nothing comes easy...😜😀\n",
      "#$elfiequeentitle\n",
      "Nothing comes easy elfiequeentitle\n",
      "\n",
      "Nice pose..will try it 😝\n",
      "Nice pose will try it\n",
      "\n",
      "And also, Kiran Gaware Patil with her newfound talent for mirror selfies.. 😏 (if you know what i mean) 😝\n",
      "And also Kiran Gaware Patil with her newfound talent for mirror selfies if you know what i mean\n",
      "\n",
      "Doesn't matter if i am going to the same place I'll still wear the same shirt.\n",
      "I can wear one shirt for years 😝😂\n",
      "Doesn t matter if i am going to the same place I ll still wear the same shirt I can wear one shirt for years\n",
      "\n",
      "But sometimes parfume also can't covering that smell 😜😃\n",
      "But sometimes parfume also can t covering that smell\n",
      "\n",
      "yeh....kind of........ but it depends which cloths make us comfortable.... so you must also wear the same cloths till it get dirt 😉😉😉.\n",
      "yeh kind of but it depends which cloths make us comfortable so you must also wear the same cloths till it get dirt\n",
      "\n",
      "Its big proud 😜😜\n",
      "Its big proud\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "for tweet in df['tweet'].head(20):\n",
    "#     print(tweet)\n",
    "    tweet = cleanse_links(tweet)\n",
    "#     tweet = cleanse_tags_mentions(tweet)\n",
    "    tweet = expand_contractions(tweet)\n",
    "#     tweet = remove_accented_chars(tweet)\n",
    "    tweet = remove_excess_whitespace(tweet)\n",
    "#     print(tweet)\n",
    "    if any(map(char_is_emoji, extract_emojis(tweet))):\n",
    "        print('!!!!!!!!!!!!!!!!')\n",
    "    print()\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbasecondae24d4f3be56c48bd9cc7fd53c4875292"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
