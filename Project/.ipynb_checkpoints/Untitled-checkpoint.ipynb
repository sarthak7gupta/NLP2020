{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'urlparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-230204276775>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munidecode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0murlparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'urlparse'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import contractions\n",
    "import unidecode\n",
    "import re\n",
    "import emoji\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sorry No Comments ..I came here to read commen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi guys. I'm so happy and proud of myself and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hahahaha your intelligence ğŸ˜œğŸ˜œğŸ˜œ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aqsa Naveed we were proud backbenchers ğŸ˜œğŸ˜œğŸ˜‚</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hemant extraordinary sketcherğŸ˜..right Ujjawal??</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5466</th>\n",
       "      <td>fuck ps3 go get a xbox 360â˜º</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5467</th>\n",
       "      <td>Happy Bithday Windows 7.. I â™¥ Windows 7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5468</th>\n",
       "      <td>I can't wait I'm soo excited! ğŸ˜€ğŸ˜€ğŸ˜€</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5469</th>\n",
       "      <td>windows live is very good, I use it more than ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5470</th>\n",
       "      <td>I really enjoyed perusing this.Inspiring â™¥â™¥â™¥</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10942 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  label\n",
       "0     Sorry No Comments ..I came here to read commen...      1\n",
       "1     Hi guys. I'm so happy and proud of myself and ...      1\n",
       "2                        Hahahaha your intelligence ğŸ˜œğŸ˜œğŸ˜œ      1\n",
       "3            Aqsa Naveed we were proud backbenchers ğŸ˜œğŸ˜œğŸ˜‚      1\n",
       "4       Hemant extraordinary sketcherğŸ˜..right Ujjawal??      1\n",
       "...                                                 ...    ...\n",
       "5466                        fuck ps3 go get a xbox 360â˜º      0\n",
       "5467            Happy Bithday Windows 7.. I â™¥ Windows 7      0\n",
       "5468                  I can't wait I'm soo excited! ğŸ˜€ğŸ˜€ğŸ˜€      0\n",
       "5469  windows live is very good, I use it more than ...      0\n",
       "5470       I really enjoyed perusing this.Inspiring â™¥â™¥â™¥      0\n",
       "\n",
       "[10942 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = ['Final_Dataset_Facebook.csv', 'Final_Dataset_Facebook_Labels.csv']\n",
    "f2 = ['Final_Dataset_Twitter.csv', 'Final_Dataset_Twitter_Labels.csv']\n",
    "\n",
    "d11, d12 = pd.read_csv(f1[0]), pd.read_csv(f1[1])\n",
    "d21, d22 = pd.read_csv(f1[0]), pd.read_csv(f1[1])\n",
    "\n",
    "df1 = pd.concat([d11, d12], axis=1)\n",
    "df2 = pd.concat([d21, d22], axis=1)\n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "df.drop(columns=['Unnamed: 1'], inplace=True)\n",
    "\n",
    "df.columns = ['tweet', 'label']\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "deselect_stop_words = ['no', 'not']\n",
    "\n",
    "for w in deselect_stop_words:\n",
    "    nlp.vocab[w].is_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def strip_links(text):\n",
    "#     link_regex    = re.compile('((https?):((//)|(\\\\\\\\))+([\\w\\d:#@%/;$()~_?\\+-=\\\\\\.&](#!)?)*)', re.DOTALL)\n",
    "#     links         = re.findall(link_regex, text)\n",
    "#     for link in links:\n",
    "#         text = text.replace(link[0], ', ')    \n",
    "#     return text\n",
    "\n",
    "URL_REGEX = re.compile(\"(http:\\/\\/www\\.|https:\\/\\/www\\.|http:\\/\\/|https:\\/\\/)?[a-z0-9]+([\\-\\.]{1}[a-z0-9]+)*\\.[a-z]{2,5}(:[0-9]{1,5})?(\\/.*)?\", re.UNICODE)\n",
    "\n",
    "def cleanse_tags_mentions(text):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])\", \" \", text).split())\n",
    "#     return re.sub(r\"(?:@\\S*|#\\S*|http(?=.*://)\\S*)\", \"\", text)\n",
    "\n",
    "def cleanse_links(text):\n",
    "    return URL_REGEX.sub(r' ',text)\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "    # cafÃ© -> cafe\n",
    "    return unidecode.unidecode(text)\n",
    "\n",
    "def expand_contractions(text):\n",
    "    # don't -> do not\n",
    "    return contractions.fix(text)\n",
    "\n",
    "def remove_excess_whitespace(text):\n",
    "    # '  ' -> ' '\n",
    "    return \" \".join(text.strip().split())\n",
    "\n",
    "def extract_emojis(sentence):\n",
    "    return [word for word in sentence.split() if str(word.encode('unicode-escape'))[2] == '\\\\' ]\n",
    "\n",
    "def char_is_emoji(character):\n",
    "    return character in emoji.UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry No Comments ..I came here to read comments ..ğŸ˜œ\n",
      "Sorry No Comments I came here to read comments\n",
      "\n",
      "Hi guys. I'm so happy and proud of myself and I thought I should share this with you!!! Today, I saw myself on TV, when I turned it off. ğŸ˜ğŸ˜\n",
      "Hi guys I m so happy and proud of myself and I thought I should share this with you Today I saw myself on TV when I turned it off\n",
      "\n",
      "Hahahaha your intelligence ğŸ˜œğŸ˜œğŸ˜œ\n",
      "Hahahaha your intelligence\n",
      "\n",
      "Aqsa Naveed we were proud backbenchers ğŸ˜œğŸ˜œğŸ˜‚\n",
      "Aqsa Naveed we were proud backbenchers\n",
      "\n",
      "Hemant extraordinary sketcherğŸ˜..right Ujjawal??\n",
      "Hemant extraordinary sketcher right Ujjawal\n",
      "\n",
      "Boys should respect them..!! ğŸ˜œğŸ”«\n",
      "Boys should respect them\n",
      "\n",
      "Your love broğŸ˜œ\n",
      "Your love bro\n",
      "\n",
      "Bro u r handsome ğŸ˜ğŸ¤£ğŸ¤£\n",
      "Bro you r handsome\n",
      "\n",
      "This talent I don't have.. pls teach me PraniğŸ˜œ\n",
      "This talent I don t have pls teach me Prani\n",
      "\n",
      "Sunny Yadav wow wat an assumptionğŸ˜\n",
      "Sunny Yadav wow wat an assumption\n",
      "\n",
      "I will try my best for u drlingğŸ˜œğŸ˜‚\n",
      "I will try my best for you drling\n",
      "\n",
      "U can do this, I trust you ğŸ˜œ\n",
      "you can do this I trust you\n",
      "\n",
      "Learning from my guru.. \"Happy teacher's Day \"ğŸ˜\n",
      "Learning from my guru Happy teacher s Day\n",
      "\n",
      "Nothing comes easy...ğŸ˜œğŸ˜€\n",
      "#$elfiequeentitle\n",
      "Nothing comes easy elfiequeentitle\n",
      "\n",
      "Nice pose..will try it ğŸ˜\n",
      "Nice pose will try it\n",
      "\n",
      "And also, Kiran Gaware Patil with her newfound talent for mirror selfies.. ğŸ˜ (if you know what i mean) ğŸ˜\n",
      "And also Kiran Gaware Patil with her newfound talent for mirror selfies if you know what i mean\n",
      "\n",
      "Doesn't matter if i am going to the same place I'll still wear the same shirt.\n",
      "I can wear one shirt for years ğŸ˜ğŸ˜‚\n",
      "Doesn t matter if i am going to the same place I ll still wear the same shirt I can wear one shirt for years\n",
      "\n",
      "But sometimes parfume also can't covering that smell ğŸ˜œğŸ˜ƒ\n",
      "But sometimes parfume also can t covering that smell\n",
      "\n",
      "yeh....kind of........ but it depends which cloths make us comfortable.... so you must also wear the same cloths till it get dirt ğŸ˜‰ğŸ˜‰ğŸ˜‰.\n",
      "yeh kind of but it depends which cloths make us comfortable so you must also wear the same cloths till it get dirt\n",
      "\n",
      "Its big proud ğŸ˜œğŸ˜œ\n",
      "Its big proud\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "for tweet in df['tweet'].head(20):\n",
    "#     print(tweet)\n",
    "    tweet = cleanse_links(tweet)\n",
    "#     tweet = cleanse_tags_mentions(tweet)\n",
    "    tweet = expand_contractions(tweet)\n",
    "#     tweet = remove_accented_chars(tweet)\n",
    "    tweet = remove_excess_whitespace(tweet)\n",
    "#     print(tweet)\n",
    "    if any(map(char_is_emoji, extract_emojis(tweet))):\n",
    "        print('!!!!!!!!!!!!!!!!')\n",
    "    print()\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbasecondae24d4f3be56c48bd9cc7fd53c4875292"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
